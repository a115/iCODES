./icds/llm_interface.py
from tenacity import retry, stop_after_attempt, retry_if_exception_type

from icds.settings import settings
from openai import OpenAI, APIConnectionError
import tiktoken


@retry(
    stop=stop_after_attempt(3),
    retry=retry_if_exception_type(APIConnectionError),
)
def _ask_gpt(client, model, messages):
    response = client.chat.completions.create(
        model=model,
        messages=messages,
    )
    analysis = response.choices[0].message.content
    return analysis


def max_tokens_for_model(model: str = settings.DEFAULT_MODEL) -> int:
    tokens_per_model = {
        "gpt-3.5-turbo": 16385
    }  # TODO: Build a more useful mapping of models to token limits
    return tokens_per_model.get(model, 8192)


def num_tokens_from_messages(messages, model=settings.DEFAULT_MODEL):
    encoding = tiktoken.encoding_for_model(model)
    return sum(
        len(encoding.encode(value))
        for message in messages
        for value in message.values()
    )


def truncate_tokens(
    messages: list[dict], model: str = settings.DEFAULT_MODEL
) -> list[dict]:
    # Truncate the last message, if needed, to make sure total tokens fit within the limit

    # First, reduce the limit by 5% to allow for some flexibility
    real_max_tokens = int(max_tokens_for_model(model) * 0.95)
    encoding = tiktoken.encoding_for_model(model)
    total_tokens = num_tokens_from_messages(messages, model)
    if total_tokens > real_max_tokens:
        last_message = messages[-1]
        tokens_to_remove = total_tokens - real_max_tokens
        encoded_last_message = encoding.encode(last_message["content"])
        truncated_last_message = encoding.decode(
            encoded_last_message[:-tokens_to_remove]
        )
        messages[-1]["content"] = truncated_last_message
    return messages


def analyse_commit(commit_info: str) -> tuple[str, str]:
    # TODO: Refactor this, so it supports other LLMs (e.g. Anthropic's Claude models)
    client = OpenAI(api_key=settings.OPENAI_API_KEY)

    system_prompt = """
    You are an experienced software engineer reviewing a commit on a git repository. Please carefully analyse the 
    commit and provide a summary of the key changes. Try your best to also infer the intent behind the changes, given 
    the available context. 
    """  # TODO: Chuck the project's README in here for context?

    prompt = (
        "Please summarise the key changes in this commit and infer the intent behind the changes: "
        + commit_info
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": prompt},
    ]

    analysis = _ask_gpt(client, settings.DEFAULT_MODEL, truncate_tokens(messages))

    summarise_prompt = "Please summarise this analysis into a single line that can be used as an improved commit message. "

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "assistant", "content": analysis},
        {"role": "user", "content": summarise_prompt},
    ]

    summary = _ask_gpt(client, settings.DEFAULT_MODEL, truncate_tokens(messages))

    return analysis, summary
./icds/models.py
from sqlmodel import Field, SQLModel, create_engine, Session, select
from datetime import datetime

from icds.settings import settings


class DbRepo(SQLModel, table=True):
    id: int = Field(primary_key=True)
    name: str
    path: str | None = None
    remote_url: str | None = None
    description: str | None = None


class RepoCommit(SQLModel, table=True):
    id: int = Field(primary_key=True)
    repo_id: int = Field(foreign_key="dbrepo.id")
    hash: str
    datetime: datetime
    author: str
    commit_message: str
    file_stats: str | None = None
    summary: str
    details: str | None = None


engine = create_engine(settings.DATABASE_URL)


def create_db_and_tables():
    SQLModel.metadata.create_all(engine)


def get_db():
    with Session(engine) as session:
        yield session


def get_repo_by_name(name: str):
    with Session(engine) as session:
        statement = select(DbRepo).where(DbRepo.name == name)
        repo = session.exec(statement).first()
        return repo
./tests/__init__.py
./icds/__init__.py
./icds/settings.py
from pydantic_settings import BaseSettings


class Settings(BaseSettings):
    DEBUG: bool = False
    DATABASE_URL: str = "sqlite:///./icodes.db"
    OPENAI_API_KEY: str = ""
    DEFAULT_MODEL: str = "gpt-3.5-turbo"


settings = Settings()
./icodes.py
from typer import Typer, echo
from pathlib import Path
from difflib import unified_diff

from loguru import logger
from git import Repo

from icds.llm_interface import analyse_commit
from icds.models import (
    create_db_and_tables,
    engine,
    DbRepo,
    RepoCommit,
    Session,
    get_repo_by_name,
)
from icds.settings import settings

app = Typer()


def extract_commit_info(commit) -> str:
    output = "RepoCommit hash: {commit}\n"
    output += "RepoCommit date: {commit.authored_datetime}\n"
    output += "Author: {commit.author}\n"
    output += "Summary: {commit.summary}\n"
    if str(commit.message).strip() != str(commit.summary).strip():
        output += "Message: {commit.message}\n"

    output += "Changes:\n\n"

    # Get the diff of the commit with its parent
    diff = commit.diff(commit.parents[0])
    for change in diff:
        output += f"{change.change_type} {change.a_path}\n"
        if change.a_path.endswith(
            "poetry.lock"
        ):  # TODO: Extract this into a more robust sanitisation function
            continue
        # logger.info(f"New blob: \n{change.a_blob.data_stream.read().decode('utf-8')}")
        # logger.info(f"Old blob: \n{change.b_blob.data_stream.read().decode('utf-8')}")
        if change.b_blob and change.a_blob:
            for line in unified_diff(
                change.b_blob.data_stream.read().decode("utf-8").splitlines(),
                change.a_blob.data_stream.read().decode("utf-8").splitlines(),
                lineterm="",
            ):
                output += line + "\n"
        output += "\n"

    return output


@app.command()
def inspect_repo(
    repo_path: Path, branch_name: str = "", n_commits: int = 10, detailed: bool = False
):
    """
    Inspect a git repository at a given path and branch. If no branch is provided, the current branch is used.
    Logs changes from the latest n_commits on the branch. If n_commits is not provided, a default maximum of 10
    commits are inspected.
    """
    repo = Repo(repo_path)
    if not branch_name:
        # Get the default branch configured for the repo
        branch_name = repo.active_branch.name
    logger.debug(f"Inspecting repo: {repo_path} on branch: {branch_name}")

    for commit in repo.iter_commits(branch_name, max_count=n_commits, reverse=True):
        commit_info = extract_commit_info(commit)
        analysis, summary = analyse_commit(commit_info)
        if detailed:
            echo(analysis + "\n")
        echo(
            f"Summary of commit #{commit} by {commit.author} from {commit.authored_datetime}: \n"
        )
        echo("\t" + summary + "\n")


@app.command()
def build_index(repo_path: Path, branch_name: str = "", n_commits: int = 10):
    """
    Build an index of the repository at the given path. If no branch is provided, the current branch is used.
    """
    repo = Repo(repo_path)
    if not branch_name:
        # Get the default branch configured for the repo
        branch_name = repo.active_branch.name

    logger.debug(
        f"Building index for repo: {repo_path} on branch: {branch_name}. Using model: {settings.DEFAULT_MODEL}. "
    )

    with Session(engine) as db:
        db_repo = _get_or_create_repo(db, repo, repo_path)
        for commit in repo.iter_commits(branch_name, max_count=n_commits, reverse=True):
            commit_info = extract_commit_info(commit)
            echo(
                f"Indexing commit {commit.hexsha} by {commit.author} from {commit.authored_datetime} ... \n"
            )
            analysis, summary = analyse_commit(commit_info)

            diff = commit.diff(commit.parents[0])
            file_stats = []
            for change in diff:
                file_stats.append(f"{change.change_type} {change.a_path}")

            commit = RepoCommit(
                repo_id=db_repo.id,
                hash=commit.hexsha,
                datetime=commit.authored_datetime,
                author=str(commit.author),
                commit_message=commit.message,
                summary=commit.summary,
                details=analysis,
                file_stats="\n".join(file_stats),
            )
            db.add(commit)
            db.commit()
            echo("\t" + summary + "\n")


def _get_or_create_repo(db, repo, repo_path):
    remote_url = repo.remotes.origin.url
    repo_name = remote_url.split("/")[-1].split(".")[0]
    db_repo = get_repo_by_name(repo_name)
    if not db_repo:
        logger.info(f"Creating a new repository record for repo '{repo_name}'")
        db_repo = DbRepo(
            name=repo_name,
            path=str(repo_path),
            remote_url=remote_url,
        )
        db.add(db_repo)
        db.commit()
    return db_repo


if __name__ == "__main__":
    create_db_and_tables()
    app()
